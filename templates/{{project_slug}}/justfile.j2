set shell := ["bash", "-uc"]

# Auto-detect build strategy
default: (_detect_build_system)

# Build all projects
build:
@echo "Building {{ project_name }}..."
{% if architecture_style == "hexagonal" %}
pnpm nx run-many --target=build --all --parallel=3
{% else %}
pnpm build
{% endif %}

# Test all projects
test:
@echo "Testing {{ project_name }}..."
@if [ -f "nx.json" ]; then \
pnpm nx run-many --target=test --all --parallel=3; \
else \
pnpm test --if-present; \
fi

# Lint all projects
lint:
@echo "Linting {{ project_name }}..."
@if [ -f "nx.json" ]; then \
pnpm nx run-many --target=lint --all; \
else \
pnpm lint --if-present; \
fi

# Development server
dev:
@echo "Starting development server for {{ project_name }}..."
@if [ -f "nx.json" ]; then \
pnpm nx run-many --target=serve --all --parallel=5; \
else \
pnpm dev --if-present || pnpm start --if-present; \
fi

spec-matrix:
pnpm spec:matrix

prompt-lint:
pnpm prompt:lint

# Setup project
setup:
@echo "Setting up {{ project_name }}..."
pnpm install
{% if include_ai_workflows == true %}
just setup-ai
{% endif %}

{% if include_ai_workflows == true %}
# Setup AI workflows
setup-ai:
@echo "Setting up AI workflows..."
python3 tools/temporal-db/init.py

# Initialize temporal database
db-init:
python3 tools/temporal-db/init.py

# Backup temporal database
db-backup:
python3 tools/temporal-db/backup.py

# Customize copilot instructions interactively
customize-instructions:
@echo "ğŸ¤– Interactive Copilot Instructions Customization"
@echo "=================================================="
@echo ""
@echo "This will guide you through customizing .github/copilot-instructions.md"
@echo "for your project. Answer questions about your:"
@echo " - Project type and tech stack"
@echo " - Architecture and domain"
@echo " - Team size and development practices"
@echo " - Testing, security, and deployment approaches"
@echo ""
@echo "You can also use the 'meta.customize-instructions' chat mode in VS Code."
@echo ""
@echo "Press Enter to continue when ready..."
@read
@echo ""
@echo "Opening .github/prompts/customize.copilot-instructions.prompt.md..."
@echo "Please use this prompt in your AI chat (GitHub Copilot or VS Code chat)."
@echo ""
@cat .github/prompts/customize.copilot-instructions.prompt.md

# --- AI Workflow Recipes ---
# Traceability: AI_ADR-004, AI_PRD-003, AI_SDS-003, AI_TS-004
#
# These recipes support AI-assisted development workflows as defined in:
# - .github/instructions/ai-workflows.instructions.md
# - .github/chatmodes/ (tdd.*, debug.*)
# - .github/prompts/ (TDD and debug workflow prompts)
#
# All recipes are safe to run in any environment and degrade gracefully
# when dependencies (pnpm, Nx) are not available.

# Bundle AI context for Copilot chat modes
# Collects specs, CALM architecture, and techstack into docs/ai_context_bundle
# for reference by .github/chatmodes/*.chatmode.md files
ai-context-bundle:
@echo "ğŸ“¦ Bundling AI context..."
@bash scripts/dev/bundle-context.sh docs/ai_context_bundle
@echo "âœ… Context bundle ready at docs/ai_context_bundle"

# --- Type Safety Pipeline (Bi-Directional) ---
# Flow A: DB -> TS -> Python
gen-types-ts:
@echo "ğŸ·ï¸ Generating TypeScript types from Supabase schema..."
@if command -v supabase >/dev/null 2>&1; then \
mkdir -p libs/shared/types/src; \
supabase gen types typescript --local --schema public > libs/shared/types/src/database.types.ts; \
else \
echo "âŒ supabase CLI not found. Please run 'just setup' to install devbox packages"; exit 1; \
fi

gen-types-py:
@echo "ğŸ Generating Python Pydantic models from TypeScript types..."
@if [ ! -f libs/shared/types/src/database.types.ts ]; then \
echo "âŒ TypeScript types not found. Run 'just gen-types-ts' first"; exit 1; \
fi
@mkdir -p libs/shared/types-py/src
@python3 tools/scripts/gen_py_types.py libs/shared/types/src libs/shared/types-py/src

gen-types:
@echo "ğŸ” Running Flow A type generation..."
just gen-types-ts
just gen-types-py

# --- Supabase Local Development Stack ---
# Uses Docker Compose for local Supabase database and services

# Helper to get dynamic database port from running container
_get_db_port:
@docker compose -f docker/docker-compose.supabase.yml port db 5432 2>/dev/null | cut -d: -f2 || echo "54322"

# Helper to get dynamic Studio port from running container
_get_studio_port:
@docker compose -f docker/docker-compose.supabase.yml port studio 3000 2>/dev/null | cut -d: -f2 || echo "54323"

supabase-start:
@echo "ğŸš€ Starting Supabase local stack..."
@if ! command -v docker >/dev/null 2>&1; then \
echo "âŒ Docker is required to run Supabase locally."; \
echo " Install Docker from: https://docs.docker.com/get-docker/"; \
exit 1; \
fi
@if ! docker compose version >/dev/null 2>&1; then \
echo "âŒ Docker Compose is required."; \
echo " Install Docker Compose from: https://docs.docker.com/compose/install/"; \
exit 1; \
fi
@# Copy env file if it doesn't exist
@if [ ! -f docker/.env.supabase ]; then \
cp docker/.env.supabase.example docker/.env.supabase; \
echo "ğŸ“ Created docker/.env.supabase from example"; \
fi
@# Start the stack
docker compose -f docker/docker-compose.supabase.yml --env-file docker/.env.supabase up -d
@echo "â³ Waiting for database to be ready..."
@sleep 5
@# Check if database is healthy
@docker compose -f docker/docker-compose.supabase.yml ps | grep -q "healthy" && \
echo "âœ… Supabase local stack running:" && \
echo " Database: localhost:$$(just _get_db_port)" && \
echo " Studio: http://localhost:$$(just _get_studio_port)" || \
echo "âš ï¸ Database may still be starting. Check: just supabase-status"

supabase-stop:
@echo "ğŸ›‘ Stopping Supabase local stack..."
@if [ -f docker/docker-compose.supabase.yml ]; then \
docker compose -f docker/docker-compose.supabase.yml down || true; \
fi
@echo "âœ… Supabase stack stopped"

supabase-status:
@echo "ğŸ“Š Supabase stack status:"
@if [ -f docker/docker-compose.supabase.yml ]; then \
docker compose -f docker/docker-compose.supabase.yml ps; \
else \
echo " Docker Compose file not found"; \
fi

supabase-reset:
@echo "ğŸ”„ Resetting Supabase stack (removes all data)..."
@if [ -f docker/docker-compose.supabase.yml ]; then \
docker compose -f docker/docker-compose.supabase.yml down -v; \
fi
just supabase-start
@echo "â³ Waiting for database to be ready..."
@sleep 8
just db-migrate
just db-seed
@echo "âœ… Supabase reset complete"

supabase-logs:
@echo "ğŸ“‹ Supabase logs (follow mode)..."
docker compose -f docker/docker-compose.supabase.yml logs -f

supabase-studio:
@echo "ğŸŒ Opening Supabase Studio..."
@PORT=$$(just _get_studio_port); \
echo " Studio URL: http://localhost:$$PORT"; \
if command -v xdg-open >/dev/null 2>&1; then \
xdg-open "http://localhost:$$PORT"; \
elif command -v open >/dev/null 2>&1; then \
open "http://localhost:$$PORT"; \
else \
echo " Open http://localhost:$$PORT in your browser"; \
fi

supabase-health:
@echo "ğŸ©º Checking Supabase stack health..."
@docker compose -f docker/docker-compose.supabase.yml ps --format {% raw %}'table {{.Name}} {{.Status}} {{.Ports}}'{%
endraw %}

db-migrate:
@echo "ğŸ—„ï¸ Running database migrations..."
@# Check if Supabase stack is running
@if ! docker compose -f docker/docker-compose.supabase.yml ps 2>/dev/null | grep -q "db.*running\|db.*healthy"; then \
echo "âš ï¸ Supabase database not running. Starting..."; \
just supabase-start; \
sleep 8; \
fi
@# Apply migrations using psql with dynamic port
@echo "ğŸ“ Applying migrations from supabase/migrations/..."
@PORT=$$(just _get_db_port); \
for f in supabase/migrations/*.sql; do \
if [ -f "$$f" ]; then \
echo " Applying: $$(basename $$f)"; \
PGPASSWORD=postgres psql -h localhost -p $$PORT -U postgres -d postgres -f "$$f" -q 2>&1 || { \
echo "âŒ Migration failed: $$f"; \
exit 1; \
}; \
fi; \
done
@echo "âœ… Migrations applied successfully"

db-seed:
@echo "ğŸŒ± Seeding database..."
@# Check if Supabase stack is running
@if ! docker compose -f docker/docker-compose.supabase.yml ps 2>/dev/null | grep -q "db.*running\|db.*healthy"; then \
echo "âŒ Supabase database not running. Run: just supabase-start"; \
exit 1; \
fi
@PORT=$$(just _get_db_port); \
if [ -f supabase/seed.sql ]; then \
PGPASSWORD=postgres psql -h localhost -p $$PORT -U postgres -d postgres -f supabase/seed.sql -q 2>&1 || { \
echo "âŒ Seed failed"; \
exit 1; \
}; \
echo "âœ… Database seeded successfully"; \
else \
echo "âš ï¸ No seed file found at supabase/seed.sql"; \
fi

db-migration-create NAME:
@echo "ğŸ“ Creating new migration: {{NAME}}"
@TIMESTAMP=$$(date +%Y%m%d%H%M%S); \
FILENAME="supabase/migrations/$${TIMESTAMP}_{{NAME}}.sql"; \
echo "-- Migration: {{NAME}}" > "$$FILENAME"; \
echo "-- Created: $$(date -Iseconds)" >> "$$FILENAME"; \
echo "" >> "$$FILENAME"; \
echo "-- Add your SQL statements here" >> "$$FILENAME"; \
echo "âœ… Created: $$FILENAME"

db-psql:
@echo "ğŸ”Œ Connecting to database..."
@PORT=$$(just _get_db_port); PGPASSWORD=postgres psql -h localhost -p $$PORT -U postgres -d postgres

db-tables:
@echo "ğŸ“‹ Listing tables in public schema..."
@PORT=$$(just _get_db_port); PGPASSWORD=postgres psql -h localhost -p $$PORT -U postgres -d postgres -c "\dt public.*"

db-describe TABLE:
@echo "ğŸ“ Describing table: {{TABLE}}"
@PORT=$$(just _get_db_port); PGPASSWORD=postgres psql -h localhost -p $$PORT -U postgres -d postgres -c "\d+
public.{{TABLE}}"


# Flow B: Python -> OpenAPI -> TypeScript
gen-api-spec:
@echo "ğŸ“œ Generating OpenAPI spec from FastAPI..."
@# Assumes the app name is '{{ app_name }}' - adjust if multiple apps
@mkdir -p apps/{{ app_name }}
@# We use a temporary script to dump the openapi.json
@echo "import json; from apps.{{ app_name }}.main import app; print(json.dumps(app.openapi(), indent=2))" >
tmp_gen_openapi.py
@PYTHONPATH=. python3 tmp_gen_openapi.py > apps/{{ app_name }}/openapi.json
@rm tmp_gen_openapi.py
@echo "âœ… Generated apps/{{ app_name }}/openapi.json"

gen-api-client:
@echo "ğŸ”Œ Generating TypeScript client from OpenAPI spec..."
@if [ ! -f apps/{{ app_name }}/openapi.json ]; then \
echo "âŒ OpenAPI spec not found. Run 'just gen-api-spec' first"; exit 1; \
fi
@mkdir -p libs/shared/web/src/lib/api-client
@# Use openapi-generator-cli (requires java)
@npx @openapitools/openapi-generator-cli generate \
-i apps/{{ app_name }}/openapi.json \
-g typescript-fetch \
-o libs/shared/web/src/lib/api-client \
--additional-properties=typescriptThreePlus=true,supportsES6=true
@echo "âœ… Generated API client in libs/shared/web/src/lib/api-client"

check-types:
@echo "ğŸ” Checking generated types are committed and up to date..."
@# Check Flow A
@just gen-types > /dev/null 2>&1 || true
@if ! git diff --exit-code -- libs/shared/types/src/database.types.ts; then \
echo "âŒ TypeScript types (Flow A) are out of date."; exit 1; \
fi
@if ! git diff --exit-code -- libs/shared/types-py/src/models.py; then \
echo "âŒ Python types (Flow A) are out of date."; exit 1; \
fi
@# Check Flow B
@just gen-api-spec > /dev/null 2>&1 || true
@if ! git diff --exit-code -- apps/{{ app_name }}/openapi.json; then \
echo "âŒ OpenAPI spec (Flow B) is out of date."; exit 1; \
fi
@echo "âœ… All types are up to date"


# --- TDD Workflow (Red-Green-Refactor) ---
# Usage: Open corresponding chat mode and follow the workflow
# Context: Reference docs/ai_context_bundle for project context

tdd-red:
@echo "ğŸ”´ Red Phase: Write failing tests from specs."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: tdd.red"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Write failing tests that define expected behavior"
@echo ""

tdd-green:
@echo "ğŸŸ¢ Green Phase: Implement minimal code to pass tests."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: tdd.green"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Write minimal implementation to make tests pass"
@echo ""

tdd-refactor:
@echo "â™»ï¸ Refactor Phase: Improve design while keeping tests green."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: tdd.refactor"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Optimize code without changing behavior"
@echo ""

# --- Debug Workflow (Start-Repro-Isolate-Fix-Refactor-Regress) ---
# Usage: Open corresponding chat mode and follow the workflow
# Context: Reference docs/ai_context_bundle for project context

debug-start:
@echo "ğŸ› Debug Start: Normalize bug report and plan reproduction."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.start"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Document the bug and plan reproduction"
@echo ""

debug-repro:
@echo "ğŸ› Debug Repro: Write failing test to reproduce the issue."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.repro"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Create minimal reproduction test"
@echo ""

debug-isolate:
@echo "ğŸ› Debug Isolate: Narrow root cause using diffs/instrumentation."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.isolate"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Add logging/instrumentation to find root cause"
@echo ""

debug-fix:
@echo "ğŸ› Debug Fix: Apply minimal change to make tests pass."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.fix"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Implement minimal fix for the issue"
@echo ""

debug-refactor:
@echo "â™»ï¸ Debug Refactor: Clean up the fix and remove instrumentation."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.refactor"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Improve fix quality and remove debug code"
@echo ""

debug-regress:
@echo "ğŸ§ª Debug Regress: Run full regression to ensure stability."
@echo ""
@echo "Next steps:"
@echo " 1. Open chat mode: debug.regress"
@echo " 2. Reference docs/ai_context_bundle"
@echo " 3. Verify no regressions were introduced"
@echo ""

# --- AI Validation & Scaffolding ---

# Validate code quality using available tooling
# Safe to run: degrades gracefully if pnpm or Nx are not available
# Runs: AGENT link checker, pre-commit, lint, typecheck, and tests (if configured)
ai-validate:
@echo "ğŸ” Validating project..."
@echo "Running AGENT.md link checker..."
@python3 tools/check_agent_links.py || true
@echo "Running pre-commit hooks..."
@if command -v pre-commit > /dev/null 2>&1; then \
pre-commit run --all-files || true; \
else \
echo "âš ï¸ pre-commit not found. Skipping pre-commit hooks."; \
fi
@if command -v pnpm > /dev/null 2>&1; then \
if [ -f package.json ] && grep -q '"lint"' package.json; then \
echo "Running lint..."; \
pnpm run lint || true; \
else \
echo "âš ï¸ No 'lint' script found in package.json. Skipping lint."; \
fi; \
if [ -f package.json ] && grep -q '"typecheck"' package.json; then \
echo "Running typecheck..."; \
pnpm run typecheck || true; \
else \
echo "âš ï¸ No 'typecheck' script found in package.json. Skipping typecheck."; \
fi; \
if pnpm exec nx --version > /dev/null 2>&1; then \
echo "Running tests..."; \
pnpm exec nx run-many --target=test --all || true; \
else \
echo "âš ï¸ Nx not available or no projects to test."; \
fi; \
else \
echo "âš ï¸ pnpm not found. Skipping validation."; \
echo "Run 'just setup' to install dependencies."; \
fi
@echo "âœ… Validation complete"

# Scaffold new code using Nx generators
# Thin wrapper around 'nx generate' with helpful error messages
# Usage: just ai-scaffold name=@nx/js:lib
ai-scaffold name="":
@if [ -z "{{name}}" ]; then \
echo "Usage: just ai-scaffold name=<generator>"; \
	echo ""; \
	echo "Examples:"; \
	echo " just ai-scaffold name=@nx/js:lib"; \
	echo " just ai-scaffold name=@nx/react:component"; \
	echo ""; \
	exit 1; \
	else \
	if command -v pnpm > /dev/null 2>&1; then \
	echo "ğŸ—ï¸ Running: pnpm exec nx g {{name}}"; \
	pnpm exec nx g {{name}}; \
	else \
	echo "âŒ pnpm not found."; \
	echo "Please run: just setup"; \
	exit 1; \
	fi; \
	fi

	# --- Documentation Generation ---
	docs-generate PROJECT_NAME="{{ project_name }}":
	@echo "ğŸ“š Generating comprehensive documentation..."
	@if [ -f cli/docs.js ]; then \
	node cli/docs.js generate \
	--project-name "{{PROJECT_NAME}}" \
	--description "Modern application with hexagonal architecture and domain-driven design" \
	--domains core,user,billing \
	--frameworks next,fastapi \
	--output-dir docs/generated \
	--include-ai; \
	else \
	echo "âš ï¸ cli/docs.js not found. Skipping documentation generation."; \
	fi

	docs-templates PROJECT_NAME="{{ project_name }}" OUTPUT_DIR="docs":
	@echo "ğŸ“ Generating documentation templates..."
	@if [ -f cli/docs.js ]; then \
	node cli/docs.js templates \
	--project-name "{{PROJECT_NAME}}" \
	--domains core,user,billing \
	--frameworks next,fastapi \
	--output-dir "{{OUTPUT_DIR}}" \
	--include-ai; \
	else \
	echo "âš ï¸ cli/docs.js not found. Skipping documentation templates."; \
	fi

	docs-validate:
	@echo "ğŸ§ª Validating documentation..."
	@if [ -f cli/docs.js ]; then \
	node cli/docs.js validate \
	--output-dir docs/generated; \
	else \
	echo "âš ï¸ cli/docs.js not found. Skipping documentation validation."; \
	fi

	docs-serve PORT="8000":
	@echo "ğŸ“š Serving documentation on port {{PORT}}..."
	@if [ -d docs/generated ]; then \
	python3 -m http.server {{PORT}} -d docs/generated; \
	else \
	echo "âš ï¸ docs/generated directory not found. Run 'just docs-generate' first."; \
	fi

	docs-clean:
	@echo "ğŸ§¹ Cleaning generated documentation..."
	rm -rf docs/generated docs/temp
	@echo "âœ… Documentation cleaned"

	{% endif %}

	_detect_build_system:
	#!/usr/bin/env bash
	if [ -f "nx.json" ]; then
	just build
	else
	pnpm build
	fi
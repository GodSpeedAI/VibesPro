# {{ project_name }} Prompt Optimizer

ML-powered token counting and prompt optimization system following hexagonal architecture and DDD principles.

## Overview

This library provides:
- Accurate token counting using tiktoken
- ML-powered prompt effectiveness analysis
- Intelligent prompt optimization
- Temporal learning from usage patterns
- Cost estimation for different AI models

## Architecture

The system follows hexagonal architecture with clear separation of concerns:

```
{{ project_name }}/
├── domain/               # Business logic and domain models
│   ├── entities/        # Core business entities
│   ├── value_objects/   # Immutable value objects
│   ├── services/        # Domain services
│   └── repositories/    # Repository interfaces
├── application/         # Use cases and application logic
│   ├── ports/          # Interface definitions
│   └── use_cases/      # Application use cases
└── infrastructure/     # External adapters
    └── adapters/       # Concrete implementations
```

## Domain Layer

### Entities

- **Prompt**: Core entity representing a text prompt with metadata
- **TokenCount**: Entity containing token analysis results
- **EffectivenessScore**: Entity with ML-generated effectiveness metrics

### Value Objects

- **OptimizationGoal**: Immutable optimization objective (clarity, conciseness, etc.)
- **AIModel**: Immutable AI model specification with pricing

## Application Layer

### Use Cases

- **AnalyzePromptUseCase**: Analyze prompt effectiveness and token usage
- **OptimizePromptUseCase**: Generate optimized version of a prompt

### Ports

- **TokenCounterPort**: Interface for token counting services
- **TemporalDatabasePort**: Interface for storing temporal data

## Infrastructure Layer

### Adapters

- **TiktokenAdapter**: Implements token counting using tiktoken library
- **SledTemporalDatabaseAdapter**: Implements temporal storage using sled database

## Usage Examples

### Basic Analysis

```python
from {{ package_path }}.application.use_cases.analyze_prompt_use_case import AnalyzePromptUseCase
from {{ package_path }}.infrastructure.adapters.tiktoken_adapter import TiktokenAdapter
from {{ package_path }}.infrastructure.adapters.sled_temporal_database_adapter import SledTemporalDatabaseAdapter
from {{ package_path }}.domain.entities.prompt import Prompt
from {{ package_path }}.domain.value_objects.ai_model import AIModel

# Setup
token_counter = TiktokenAdapter()
database = SledTemporalDatabaseAdapter("./temporal_db")
use_case = AnalyzePromptUseCase(token_counter, database)

# Analyze prompt
prompt = Prompt.create(content="Your prompt text here")
model = AIModel.GPT4
result = await use_case.execute(prompt, model)

print(f"Token count: {result.token_count.count}")
print(f"Effectiveness score: {result.effectiveness_score.overall_score}")
```

### Prompt Optimization

```python
from {{ package_path }}.application.use_cases.optimize_prompt_use_case import OptimizePromptUseCase
from {{ package_path }}.domain.value_objects.optimization_goal import OptimizationGoal

# Setup optimization use case
optimize_use_case = OptimizePromptUseCase(token_counter, database)

# Optimize for clarity
goal = OptimizationGoal.CLARITY
result = await optimize_use_case.execute(prompt, goal, model)

print(f"Original: {result.original_prompt.content}")
print(f"Optimized: {result.optimized_prompt.content}")
print(f"Token savings: {result.improvement_metrics['token_reduction']}")
```

### CLI Usage

The library includes enhanced CLI tools:

```bash
# Analyze a prompt
./measure_tokens.sh my_prompt.txt --analyze

# Optimize for conciseness
./measure_tokens.sh my_prompt.txt --optimize --goal conciseness

# Get JSON output for integration
./measure_tokens.sh my_prompt.txt --analyze --format json
```

## Configuration

The system can be configured through environment variables:

```bash
# Database configuration
export PROMPT_OPTIMIZER_DB_PATH="./temporal_db"

# Model configuration
export PROMPT_OPTIMIZER_DEFAULT_MODEL="gpt-4"

# Analysis configuration
export PROMPT_OPTIMIZER_LEARNING_ENABLED="true"
```

## Dependencies

Core dependencies:
- `tiktoken` - Token counting
- `sled` - Temporal database (Rust binding)
- `asyncio` - Async support

Optional dependencies:
- `numpy` - ML computations
- `pandas` - Data analysis

## Testing

The library includes comprehensive tests following TDD principles:

```bash
# Run all tests
pytest tests/

# Run specific layer tests
pytest tests/domain/
pytest tests/application/
pytest tests/infrastructure/

# Run with coverage
pytest --cov={{ package_path }} tests/
```

## Contributing

1. Follow hexagonal architecture principles
2. Maintain strict type safety with mypy
3. Write tests following TDD (RED → GREEN → REFACTOR)
4. Use domain-driven design patterns
5. Keep dependencies pointing inward (domain ← application ← infrastructure)

## License

{{ license }}

---

Generated with VibePro prompt-optimizer template v{{ template_version }}
